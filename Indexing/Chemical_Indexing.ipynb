{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chemical_Indexing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNw4pR8D8poG6ZlFVdhWeK/"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4DhFSZDO98-"
      },
      "outputs": [],
      "source": [
        "#build dataframe for data \n",
        "DATA = 'prefixed_train.xlsx'\n",
        "df = pd.read_excel (DATA)\n",
        "print (df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#shuffle data\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df"
      ],
      "metadata": {
        "id": "xg9zdtMZPDl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols=[0,5,6,9]\n",
        "X = df.drop(df.columns[cols], axis=1)"
      ],
      "metadata": {
        "id": "3blUxnyDPUrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "gbpXiAklPdDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnt_df = pd.read_excel('train_depth.xlsx')\n",
        "\n",
        "def decide_parents_by_depth(cnt_df, X):\n",
        "  chemical_to_depth={}\n",
        "  for idx, row in cnt_df.iterrows():\n",
        "    if row['Chemical'] not in chemical_to_depth:\n",
        "      chemical_to_depth[row['Chemical']]=[]\n",
        "    chemical_to_depth[row['Chemical']] .append(row['Depth'])\n",
        "    chemical_to_depth[row['Chemical']]=list(set(chemical_to_depth[row['Chemical']]))\n",
        "  #add depth as a feature\n",
        "  depth=[]\n",
        "  for idx,row in X.iterrows(): \n",
        "    d = chemical_to_depth[row['Chemical']]\n",
        "    string_d = [str(elem) for elem in d]\n",
        "    depth.append(string_d)\n",
        "  X['Depth']=depth\n",
        "  depth_X= X[['Depth']].join(X.Depth.str.join('|').str.get_dummies().add_prefix('depth_'))\n",
        "  X = pd.concat([X,depth_X],axis=1) #merge them together \n",
        "  X = X.drop(['Depth'], axis=1)\n",
        "  X\n",
        "  return X\n",
        "\n",
        "def drop_parents_by_depth(cnt_df, not_remove_cols,X):\n",
        "  #drop the chemicals by the depth\n",
        "  toRemove=[]\n",
        "  #not_remove_col=['depth_4','depth_5','depth_6','depth_7','depth_8','depth_9','depth_10']\n",
        "  not_remove_col = not_remove_cols \n",
        "  for idx, row in X.iterrows():\n",
        "    if row['Appeared']==0 and row['Indexing(T/F)']==0: #added as a parent but is not an indexing chemical\n",
        "      if row['depth_0']==1 or row['depth_1']==1 or row['depth_2']==1 or row['depth_3']==1:\n",
        "        remove=True\n",
        "        for col in not_remove_col: #check if it is not contained to another column\n",
        "          if row[col]==1:\n",
        "            remove=False\n",
        "            break\n",
        "        if remove is True:\n",
        "          toRemove.append(idx)\n",
        "\n",
        "  #drop \n",
        "  X= X.drop(X.index[toRemove])\n",
        "  X = X.loc[:, ~X.columns.str.startswith('depth')]\n",
        "  return X \n",
        "\n",
        "X=decide_parents_by_depth(cnt_df,X)\n",
        "X\n",
        "#TO CHANGE:\n",
        "#not_remove_col=['depth_4','depth_5','depth_6','depth_7','depth_8','depth_9'] NLMCHEM\n",
        "not_remove_col=['depth_4','depth_5','depth_6','depth_7','depth_8','depth_9','depth_10'] #BC5CDR\n",
        "X = drop_parents_by_depth(cnt_df,not_remove_col,X )"
      ],
      "metadata": {
        "id": "98HLiSgyPird"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = X['Indexing(T/F)']\n",
        "X = X.drop(['Chemical','Appeared','Indexing(T/F)'], axis=1) #use the hierarchy prefix instead of the chemical identifier\n",
        "X"
      ],
      "metadata": {
        "id": "znzqP7ppPuZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Target encoding - after the split \n",
        "!pip install --upgrade category_encoders\n",
        "from category_encoders import TargetEncoder\n",
        "encoder = TargetEncoder()\n",
        "#X is training data\n",
        "X = encoder.fit_transform(X,y)"
      ],
      "metadata": {
        "id": "lZMBFOXxRL9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to handle class imbalance\n",
        "#equally penalize under or over-represented classes in the training set.\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y),y=y)\n",
        "\n",
        "print(\"Class Weights:\",class_weights)\n",
        "\n",
        "class_weight = { 0: class_weights[0] , 1: class_weights[1]}"
      ],
      "metadata": {
        "id": "s5ZynSDvRPS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y,\n",
        "                                                stratify=y,  #set the class ratio equal as the original training set\n",
        "                                                test_size=0.20)"
      ],
      "metadata": {
        "id": "oxL_k0b5RUuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import tensorflow as tf\n",
        "from keras.models import load_model\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_fscore', patience=5, verbose=1,factor=0.5, min_lr=0.0001)"
      ],
      "metadata": {
        "id": "o4lcE52ORe2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.optimizers import SGD,Adam,RMSprop\n",
        "from keras.regularizers import l2\n",
        "#creating model\n",
        "def create_model(optimizer='adam', activation = 'relu',units=1, hidden_layers = 1, regularizer=0.0, learning_rate = 0.1, dropout=False):\n",
        "  # Initialize the constructor\n",
        "  model = Sequential()\n",
        "  # Add an input layer\n",
        "  model.add(Dense(units,input_dim = X.shape[1], activation=activation,kernel_initializer='he_uniform'))\n",
        "  # Add one hidden layer\n",
        "  for i in range(hidden_layers):\n",
        "    model.add(Dense(units*(i+2),activation=activation,  kernel_regularizer=l2(regularizer)))\n",
        "    if dropout is True:\n",
        "      model.add(Dropout(0.2))\n",
        "  # Add an output layer \n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  #add an optimizer\n",
        "  if optimizer is 'adam':\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "  elif optimizer is 'sgd':\n",
        "    optimizer=SGD(learning_rate=lr)\n",
        "  elif optimizer is 'rmsprop':\n",
        "    optimizer = RMSprop(learning_rate=learning_rate)\n",
        "  #compile model\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "-lcXEDNbSCQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(units=20, hidden_layers = 3, dropout=False, learning_rate=0.0003)"
      ],
      "metadata": {
        "id": "ERyfi_3URjaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, batch_size=64, epochs=15, validation_data=(X_val,y_val), shuffle=True, callbacks=[callback,learning_rate_reduction], class_weight = class_weight)\n",
        "model.save('nlm+cdr_trained_model.h5') "
      ],
      "metadata": {
        "id": "QzUDWcp4RjU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation on the dev set \n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "y_pred1 = model.predict(X_test)\n",
        "y_pred=[]\n",
        "for elem in y_pred1:\n",
        "  if elem>0.50:\n",
        "    y_pred.append([1])\n",
        "  else:\n",
        "    y_pred.append([0])\n"
      ],
      "metadata": {
        "id": "ji-5j2B2Rotd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_test_performance(answer,pred):\n",
        "    #print precision, recall\n",
        "    print(\"Precision:\",metrics.precision_score(answer, pred))\n",
        "    print(\"Recall:\",metrics.recall_score(answer, pred))\n",
        "    print(\"F1:\",metrics.f1_score(answer,pred))\n",
        "    #printing out confusion matrix \n",
        "    print(confusion_matrix(answer,pred))\n",
        "    print(classification_report(answer,pred))\n",
        "\n",
        "get_test_performance(y_test,y_pred)"
      ],
      "metadata": {
        "id": "PHwd6JbJR5Et"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}